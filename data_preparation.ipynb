{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding & Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "\n",
    "client = 'TOOL_CLIENT.csv'\n",
    "sales  = 'TOOL_SALES.csv'\n",
    "joint = 'TOOL_JOINT.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_client = pd.read_csv(client)\n",
    "df_sales = pd.read_csv(sales)\n",
    "\n",
    "df = pd.merge(df_client, df_sales, on='CLIENT_ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case and replace spaces with underscores in column names\n",
    "original_columns = df.columns\n",
    "renamed_columns = [col.lower().replace(\" \", \"_\") for col in original_columns]\n",
    "column_mapping = dict(zip(original_columns, renamed_columns))\n",
    "df.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting date columns to datetime\n",
    "df['client_create_date'] = pd.to_datetime(df['client_create_date'])\n",
    "df['yyyymm'] = pd.to_datetime(df['yyyymm'].astype(str), format='%Y%m')\n",
    "\n",
    "# converting other columns to appropriate data types\n",
    "df['client_id'] = df['client_id'].astype(str)\n",
    "df['cancelled'] = df['cancelled'] == 'X'\n",
    "df['unit'] = df['unit'] == 'P'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column for identifie the unique sales\n",
    "df['sales_id'] = df['client_id'].astype(str) + '_' + df['yyyymm'].dt.strftime('%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding new variables to the main dataframe\n",
    "n_purchases = df.groupby('client_id')['sales_id'].nunique()   # counting unique sales for each client\n",
    "sales_net = df.groupby('sales_id')['net'].sum()   # summarizing the net sales by sales_id\n",
    "\n",
    "time_diff = df[['client_id', 'sales_id', 'yyyymm']].drop_duplicates()   # extracting time between purchases\n",
    "time_diff['time_diff_prec'] = time_diff.groupby('client_id')['yyyymm'].diff().dt.days\n",
    "time_diff['time_diff_next'] = (time_diff.groupby('client_id')['yyyymm'].shift(-1) - time_diff['yyyymm']).dt.days\n",
    "\n",
    "# merging the new variables to the main dataframe\n",
    "df['n_purchases'] = df['client_id'].map(n_purchases)   # adding the number of purchases\n",
    "df['sales_net'] = df['sales_id'].map(sales_net)   # adding the net sales\n",
    "df['time_diff_prec'] = df['sales_id'].map(time_diff.set_index('sales_id')['time_diff_prec'])   # adding the time difference\n",
    "df['time_diff_next'] = df['sales_id'].map(time_diff.set_index('sales_id')['time_diff_next'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['unit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.copy()   # creating a copy of the main dataframe for modeling\n",
    "\n",
    "# dropping columns that are not needed for modeling\n",
    "df_model.drop(df_model[df_model['unit'] == False].index, inplace=True)   # dropping the canceled orders\n",
    "df_model.drop('unit', axis=1, inplace=True)    # dropping the canceled column\n",
    "df_model.drop(df_model[df_model['cancelled'] == True].index, inplace=True)   # dropping the canceled orders\n",
    "df_model.drop('cancelled', axis=1, inplace=True)    # dropping the canceled column\n",
    "\n",
    "df_model.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the target variable\n",
    "df_model['target'] = np.where(df_model['time_diff_next'] > 730, 1, 0)\n",
    "df_model.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.drop(df_model[df_model['time_diff_next'] <= 730].index, inplace=True)  # dropping the sales with less than 2 years between them\n",
    "df_model.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.to_csv('DF_Model.csv', index=False)   # saving the model dataframe to a csv file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
